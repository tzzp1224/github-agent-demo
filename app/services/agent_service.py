# æ–‡ä»¶è·¯å¾„: app/services/agent_service.py
import json
import asyncio
import traceback
from app.core.config import settings
from app.utils.llm_client import client
from app.services.github_service import get_repo_structure, get_file_content
from app.services.vector_service import store_manager
from app.services.chunking_service import PythonASTChunker

# === è¾…åŠ©å‡½æ•°ï¼šæ™ºèƒ½æ–‡ä»¶æ ‘ç”Ÿæˆ ===
def generate_smart_file_list(file_list, max_token_limit=1000):
    """
    ç­–ç•¥ï¼š
    1. ä¼˜å…ˆä¿ç•™ README å’Œæ ¹ç›®å½•æ–‡ä»¶ã€‚
    2. å¦‚æœæ–‡ä»¶æ€»æ•°è¾ƒå°‘ (< 300)ï¼Œç›´æ¥è¿”å›å…¨é‡åˆ—è¡¨ã€‚
    3. å¦‚æœæ–‡ä»¶å¾ˆå¤šï¼Œè¿‡æ»¤æ‰éæ ¸å¿ƒåç¼€ï¼Œä¸”ä»…ä¿ç•™å‰ N ä¸ªã€‚
    """
    core_extensions = ('.py', '.js', '.ts', '.go', '.java', '.cpp', '.h', '.rs', '.md', '.json', '.yml', '.yaml', 'Dockerfile')
    priority_files = [f for f in file_list if f.lower().endswith("readme.md")]
    code_files = [f for f in file_list if f.endswith(core_extensions) and f not in priority_files]
    total_files_count = len(file_list)
    
    if total_files_count < 300:
        final_list = priority_files + code_files
        return "\n".join(final_list[:500])
    else:
        truncated_list = priority_files + code_files[:400]
        remaining = len(code_files) - 400
        result = "\n".join(truncated_list)
        if remaining > 0:
            result += f"\n... (and {remaining} more files hidden)"
        return result

async def agent_stream(repo_url: str, session_id: str):
    """
    Agent ReAct å·¥ä½œæµï¼šæ„ŸçŸ¥ -> (æ€è€ƒ -> è¡ŒåŠ¨ -> è§‚å¯Ÿ) * N -> æŠ¥å‘Š
    """
    short_id = session_id[-6:] if session_id else "unknown"
    yield json.dumps({"step": "init", "message": f"ğŸš€ [Session: {short_id}] æ­£åœ¨è¿æ¥ GitHub..."})
    await asyncio.sleep(0.5)
    
    try:
        # 1. åˆå§‹åŒ–èµ„æº
        vector_db = store_manager.get_store(session_id)
        
        # === æ ¸å¿ƒä¿®å¤ç‚¹ï¼šå…ˆ Resetï¼Œå†èµ‹å€¼ URL ===
        # ä¹‹å‰çš„é¡ºåºåäº†ï¼Œå¯¼è‡´ reset æŠŠ url æ¸…ç©ºäº†
        vector_db.reset_collection() 
        vector_db.repo_url = repo_url  # <--- å¿…é¡»æ”¾åœ¨ reset ä¹‹åï¼
        
        chunker = PythonASTChunker(min_chunk_size=50)

        # 2. è·å–æ–‡ä»¶æ ‘
        file_list = get_repo_structure(repo_url)
        if not file_list:
            yield json.dumps({"step": "error", "message": "âŒ æ— æ³•è·å–æ–‡ä»¶åˆ—è¡¨ã€‚"})
            return

        yield json.dumps({"step": "fetched", "message": f"ğŸ“¦ å‘ç° {len(file_list)} ä¸ªæ–‡ä»¶ï¼Œæ­£åœ¨æ„å»ºæ–‡ä»¶è§†å›¾..."})
        
        file_tree_str = generate_smart_file_list(file_list)
        
        # 3. ReAct å¾ªç¯é…ç½®
        MAX_ROUNDS = 3
        visited_files = set()
        context_summary = ""
        
        readme_file = next((f for f in file_list if f.lower().endswith("readme.md")), None)

        for round_idx in range(MAX_ROUNDS):
            # --- Phase A: æ€è€ƒ (Reasoning) ---
            yield json.dumps({"step": "thinking", "message": f"ğŸ•µï¸ [Round {round_idx+1}/{MAX_ROUNDS}] æ­£åœ¨åˆ†ææ¶æ„ï¼Œè§„åˆ’é˜…è¯»è·¯å¾„..."})
            
            prompt = f"""
            You are a Source Code Auditor. 
            Goal: Analyze the **INTERNAL IMPLEMENTATION** of the project.
            
            Strict Rules:
            1. **PRIORITIZE SOURCE**: Look for folders like 'app/', 'src/', 'fastapi/', 'core/'.
            2. **Follow Imports**: If you see 'from .routing import APIRouter', you MUST read 'routing.py'.
            3. Read 'README.md' in the first round if available.
            
            Project File List (Core files):
            {file_tree_str}
            
            Files already read: {list(visited_files)}
            
            Knowledge gained (Imports/Definitions):
            {context_summary}
            
            Task:
            Select 1-3 critical files to read next.
            Return ONLY a raw JSON list.
            """
            
            if not client:
                 yield json.dumps({"step": "error", "message": "âŒ LLM Client æœªåˆå§‹åŒ–ã€‚"})
                 return

            # è°ƒç”¨ LLM å†³ç­–
            response = await asyncio.to_thread(
                client.models.generate_content,
                model=settings.MODEL_NAME, 
                contents=prompt
            )
            
            target_files = []
            try:
                text = response.text.replace("```json", "").replace("```", "").strip()
                target_files = json.loads(text)
            except:
                pass

            valid_files = [f for f in target_files if f in file_list and f not in visited_files]

            # ç¬¬ä¸€è½®å¼ºåˆ¶è¯»å– README
            if round_idx == 0 and readme_file and readme_file not in valid_files:
                valid_files.insert(0, readme_file)
                yield json.dumps({"step": "plan", "message": f"ğŸ“˜ [ç­–ç•¥] å¼ºåˆ¶è¿½åŠ é˜…è¯»: {readme_file}"})

            if not valid_files:
                yield json.dumps({"step": "plan", "message": f"ğŸ›‘ [Round {round_idx+1}] æ€è€ƒå®Œæ¯•ï¼Œåœæ­¢æ¢ç´¢ã€‚"})
                break
            
            yield json.dumps({"step": "plan", "message": f"ğŸ‘‰ [Round {round_idx+1}] å†³å®šé˜…è¯»: {valid_files}"})
            
            # --- Phase B: è¡ŒåŠ¨ (Acting) ---
            new_knowledge = ""
            
            for i, file_path in enumerate(valid_files):
                yield json.dumps({"step": "download", "message": f"ğŸ“¥ è§£ææºç : {file_path}..."})
                
                content = get_file_content(repo_url, file_path)
                if not content: continue
                
                visited_files.add(file_path)
                
                # æå– Preview
                lines = content.split('\n')[:100]
                if file_path.endswith('.md'):
                    preview = "\n".join([l for l in lines if l.strip().startswith('#')])
                else:
                    preview = "\n".join([l for l in lines if l.strip().startswith(('import', 'from', 'class', 'def'))])
                
                new_knowledge += f"\n--- File: {file_path} ---\n{preview}\n"

                # AST åˆ‡ç‰‡
                chunks = await asyncio.to_thread(chunker.chunk_file, content, file_path)
                if not chunks: continue
                
                documents = [c["content"] for c in chunks]
                metadatas = []
                for c in chunks:
                    meta = c["metadata"]
                    metadatas.append({
                        "file": meta["file"],
                        "type": meta["type"],
                        "name": meta.get("name", ""),
                        "class": meta.get("class") or ""
                    })

                if documents:
                    await asyncio.to_thread(vector_db.add_documents, documents, metadatas)
            
            # --- Phase C: è§‚å¯Ÿ (Observing) ---
            context_summary += new_knowledge
            
            yield json.dumps({"step": "indexing", "message": f"ğŸ§  [Round {round_idx+1}] çŸ¥è¯†å·²å¸æ”¶ï¼Œå‡†å¤‡ä¸‹ä¸€è½®æ€è€ƒ..."})

        # Step 4: æœ€ç»ˆæŠ¥å‘Š
        yield json.dumps({"step": "generating", "message": "ğŸ“ æ­£åœ¨æ’°å†™æŠ€æœ¯æ¶æ„æŠ¥å‘Š..."})
        
        analysis_prompt = f"""
        You are a Tech Lead.
        Files analyzed: {list(visited_files)}
        
        Code Summary (Imports & Signatures):
        {context_summary[:10000]}
        
        Write a technical report (Markdown, Chinese).
        Focus on:
        1. Project Purpose
        2. Core Architecture
        3. Key Classes & Data Flow
        """
        
        try:
            stream = client.models.generate_content_stream(
                model=settings.MODEL_NAME, contents=analysis_prompt
            )
            for chunk in stream:
                yield json.dumps({"step": "report_chunk", "chunk": chunk.text})
                await asyncio.sleep(0.02)
        except Exception:
            resp = client.models.generate_content(model=settings.MODEL_NAME, contents=analysis_prompt)
            yield json.dumps({"step": "report_chunk", "chunk": resp.text})

        yield json.dumps({"step": "finish", "message": "âœ… åˆ†æå®Œæˆï¼"})

    except Exception as e:
        traceback.print_exc()
        yield json.dumps({"step": "error", "message": f"ğŸ’¥ ç³»ç»Ÿé”™è¯¯: {str(e)}"})