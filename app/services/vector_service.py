# æ–‡ä»¶è·¯å¾„: app/services/vector_service.py
import chromadb
from chromadb.config import Settings as ChromaSettings
from app.utils.llm_client import client
from app.core.config import settings
from rank_bm25 import BM25Okapi
import re
import time

class VectorStore:
    def __init__(self, session_id: str):
        self.session_id = session_id
        self.chroma_client = chromadb.Client(ChromaSettings(anonymized_telemetry=False))
        self.collection_name = f"repo_{session_id}"
        
        # === æ–°å¢ï¼šå…ƒæ•°æ®å­˜å‚¨ ===
        self.repo_url = None       # è®°ä½ä»“åº“åœ°å€ï¼Œä¾› Chat é˜¶æ®µä¸‹è½½æ–°æ–‡ä»¶
        self.indexed_files = set() # è®°ä½å·²ç´¢å¼•çš„æ–‡ä»¶ï¼Œé¿å…é‡å¤ä¸‹è½½
        
        # Hybrid Search ç»„ä»¶
        self.bm25 = None
        self.doc_store = [] 
        
        self.reset_collection()

    def reset_collection(self):
        try:
            self.chroma_client.delete_collection(name=self.collection_name)
        except Exception:
            pass
        self.collection = self.chroma_client.create_collection(name=self.collection_name)
        self.bm25 = None
        self.doc_store = []
        self.repo_url = None
        self.indexed_files = set()
        print(f"ğŸ§¹ [Session: {self.session_id}] æ•°æ®åº“å·²é‡ç½®")

    def embed_text(self, text):
        if not client: return []
        try:
            result = client.models.embed_content(
                model=settings.EMBEDDING_MODEL,
                contents=text
            )
            return result.embeddings[0].values
        except Exception as e:
            print(f"âŒ Embedding Error: {e}")
            return []

    def _tokenize(self, text):
        return [t.lower() for t in re.split(r'[^a-zA-Z0-9]', text) if t.strip()]

    def add_documents(self, documents, metadatas):
        if not documents: return
        
        embeddings = []
        ids = []
        
        for i, doc in enumerate(documents):
            # è®°å½•å·²ç´¢å¼•çš„æ–‡ä»¶å
            self.indexed_files.add(metadatas[i]['file'])
            
            doc_id = f"{metadatas[i]['file']}_{len(self.doc_store) + i}"
            self.doc_store.append({
                "id": doc_id,
                "content": doc,
                "metadata": metadatas[i]
            })
            
            emb = self.embed_text(doc)
            if emb:
                embeddings.append(emb)
                ids.append(doc_id)

        if embeddings:
            self.collection.add(documents=documents, embeddings=embeddings, metadatas=metadatas, ids=ids)
        
        # é‡å»º BM25
        tokenized_corpus = [self._tokenize(doc['content']) for doc in self.doc_store]
        self.bm25 = BM25Okapi(tokenized_corpus)
        
        print(f"âœ… [Session: {self.session_id}] å¢é‡ç´¢å¼•å®Œæˆï¼Œå½“å‰æ–‡æ¡£æ•°: {len(self.doc_store)}")


    # === æ–°å¢æ–¹æ³•ï¼šæŒ‰æ–‡ä»¶åå¼ºåˆ¶æ£€ç´¢ ===
    def get_documents_by_file(self, file_path):
        """
        ä»å†…å­˜ doc_store ä¸­ç›´æ¥æå–æŒ‡å®šæ–‡ä»¶çš„æ‰€æœ‰åˆ‡ç‰‡ï¼Œ
        å¹¶è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼ï¼ˆåŒ…å« top-level 'file' é”®ï¼‰ã€‚
        """
        # 1. ç­›é€‰åŸå§‹æ–‡æ¡£
        raw_docs = [
            doc for doc in self.doc_store 
            if doc['metadata']['file'] == file_path
        ]
        
        # 2. æ ¼å¼åŒ–è½¬æ¢ (Fix KeyError: 'file')
        formatted_docs = []
        for d in raw_docs:
            formatted_docs.append({
                "id": d['id'],
                "content": d['content'],
                "file": d['metadata']['file'], # <--- å…³é”®ä¿®å¤ï¼šæ‰‹åŠ¨æ·»åŠ  file é”®
                "metadata": d['metadata'],
                "score": 1.0 # å¼ºåˆ¶æå–çš„è§†ä¸ºæ»¡åˆ†
            })
            
        # 3. æŒ‰è¡Œå·æ’åº
        return sorted(formatted_docs, key=lambda x: x['metadata'].get('start_line', 0))
    
    def search_hybrid(self, query, top_k=3):
        # 1. å‘é‡æ£€ç´¢ (Vector Search)
        vector_results = []
        query_embedding = self.embed_text(query)
        if query_embedding:
            chroma_res = self.collection.query(
                query_embeddings=[query_embedding], n_results=top_k * 2
            )
            if chroma_res['ids']:
                ids = chroma_res['ids'][0]
                docs = chroma_res['documents'][0]
                metas = chroma_res['metadatas'][0]
                for i in range(len(ids)):
                    vector_results.append({
                        "id": ids[i], 
                        "content": docs[i], 
                        "file": metas[i]['file'], 
                        "metadata": metas[i],  # <--- ğŸš¨ã€ä¿®å¤ç‚¹1ã€‘å¿…é¡»åŠ ä¸Šè¿™è¡Œ
                        "score": 0
                    })

        # 2. BM25 æ£€ç´¢
        bm25_results = []
        if self.bm25:
            tokenized_query = self._tokenize(query)
            doc_scores = self.bm25.get_scores(tokenized_query)
            top_n = min(len(doc_scores), top_k * 2)
            top_indices = sorted(range(len(doc_scores)), key=lambda i: doc_scores[i], reverse=True)[:top_n]
            for idx in top_indices:
                if doc_scores[idx] > 0:
                    item = self.doc_store[idx]
                    bm25_results.append({
                        "id": item["id"], 
                        "content": item["content"], 
                        "file": item["metadata"]["file"], 
                        "metadata": item["metadata"], # <--- ğŸš¨ã€ä¿®å¤ç‚¹2ã€‘å¿…é¡»åŠ ä¸Šè¿™è¡Œ
                        "score": 0
                    })

        # 3. Weighted RRF Fusion
        k = 60
        weight_vector = 1.0
        weight_bm25 = 0.3
        fused_scores = {}

        for rank, item in enumerate(vector_results):
            doc_id = item['id']
            if doc_id not in fused_scores: fused_scores[doc_id] = {"item": item, "score": 0}
            fused_scores[doc_id]["score"] += weight_vector * (1 / (k + rank + 1))
            
        for rank, item in enumerate(bm25_results):
            doc_id = item['id']
            if doc_id not in fused_scores: fused_scores[doc_id] = {"item": item, "score": 0}
            fused_scores[doc_id]["score"] += weight_bm25 * (1 / (k + rank + 1))

        sorted_results = sorted(fused_scores.values(), key=lambda x: x['score'], reverse=True)
        return [res['item'] for res in sorted_results[:top_k]]

class VectorStoreManager:
    def __init__(self):
        self.stores = {} 
        self.last_access = {} 

    def get_store(self, session_id: str) -> VectorStore:
        if session_id not in self.stores:
            print(f"ğŸ†• åˆ›å»ºæ–°ä¼šè¯: {session_id}")
            self.stores[session_id] = VectorStore(session_id)
        self.last_access[session_id] = time.time()
        return self.stores[session_id]

store_manager = VectorStoreManager()